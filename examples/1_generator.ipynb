{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.sampling import Condition\n",
    "from sdv.single_table import CopulaGANSynthesizer, CTGANSynthesizer, GaussianCopulaSynthesizer, TVAESynthesizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "data_path = Path(\"PATH_TO_ORIGINAL_DATA\")  # TODO: Change this to the path of the original data\n",
    "synt_path = Path(\"PATH_TO_SYNTHETIC_DATA_DIRECTORY\")  # TODO: Change this to the path of the synthetic data directory\n",
    "\n",
    "\n",
    "data = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "LABEL = \"TARGET_COLUMN\"  # TODO: Change this to the target column\n",
    "ID = None  # TODO: Change this to the ID column if exists\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=data[LABEL],\n",
    ")\n",
    "\n",
    "\n",
    "train_data.to_csv(data_path / \"train.csv\", index=False)\n",
    "test_data.to_csv(data_path / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data)\n",
    "metadata_dict = metadata.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose between binary or non-binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = train_data.shape[0]\n",
    "\n",
    "# If the target column is not binary, you can use the following code to create a condition\n",
    "category_counts = train_data[LABEL].value_counts()\n",
    "target_a = category_counts.get(\"TRUE_CONDITION_VALUE\", 0)\n",
    "target_b = category_counts.get(\"FALSE_CONDITION_VALUE\", 0)\n",
    "\n",
    "true_condition = Condition(num_rows=target_a, column_values={LABEL: \"TRUE_CONDITION_VALUE\"})\n",
    "false_condition = Condition(num_rows=target_b, column_values={LABEL: \"FALSE_CONDITION_VALUE\"})\n",
    "\n",
    "# IF the target column is binary, you can use the following code to create a condition and comment the above code\n",
    "# true_samples = train_data[LABEL].sum()\n",
    "# false_samples = total_samples - true_samples\n",
    "# true_condition = Condition(num_rows=true_samples, column_values={LABEL: True})\n",
    "# false_condition = Condition(num_rows=false_samples, column_values={LABEL: False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CopulaGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_gan_synthesizer = CopulaGANSynthesizer(metadata)\n",
    "copula_gan_synthesizer.fit(train_data)\n",
    "copula_gan_synthetic_data = copula_gan_synthesizer.sample_from_conditions(conditions=[true_condition, false_condition])\n",
    "copula_gan_synthetic_data.to_csv(synt_path / \"CopulaGAN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_synthesizer = CTGANSynthesizer(metadata)\n",
    "ctgan_synthesizer.fit(train_data)\n",
    "ctgan_synthetic_data = ctgan_synthesizer.sample_from_conditions(conditions=[true_condition, false_condition])\n",
    "ctgan_synthetic_data.to_csv(synt_path / \"CTGAN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_copula_synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "gaussian_copula_synthesizer.fit(train_data)\n",
    "gaussian_copula_synthetic_data = gaussian_copula_synthesizer.sample_from_conditions(\n",
    "    conditions=[true_condition, false_condition],\n",
    ")\n",
    "gaussian_copula_synthetic_data.to_csv(synt_path / \"GaussianCopula.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvae_synthesizer = TVAESynthesizer(metadata)\n",
    "tvae_synthesizer.fit(train_data)\n",
    "tvae_synthetic_data = tvae_synthesizer.sample_from_conditions(conditions=[true_condition, false_condition])\n",
    "tvae_synthetic_data.to_csv(synt_path / \"TVAE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthius.model import GaussianMultivariateSynthesizer\n",
    "\n",
    "gaussian_multivariate_synthesizer = GaussianMultivariateSynthesizer(train_data, synt_path)\n",
    "gaussian_multivariate_synthesizer.synthesize(num_sample=total_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN\n",
    "\n",
    "Based on the size of the data and its complexity, HP may need some changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthius.data import DataImputationPreprocessor\n",
    "from synthius.model import WGAN\n",
    "\n",
    "data_preprocessor = DataImputationPreprocessor(train_data)\n",
    "processed_train_data = data_preprocessor.fit_transform()\n",
    "\n",
    "n_features = processed_train_data.shape[1]\n",
    "wgan_imputer = WGAN(n_features=n_features, base_nodes=128, batch_size=512, critic_iters=5, lambda_gp=10.0, num_epochs=100_000)\n",
    "wgan_imputer.train(processed_train_data, log_interval=5_000, log_training=True)\n",
    "\n",
    "wgan_synthetic_samples = wgan_imputer.generate_samples(total_samples)\n",
    "wgan_synthetic_data = pd.DataFrame(wgan_synthetic_samples, columns=processed_train_data.columns)\n",
    "\n",
    "# --------------------- Decoding ---------------------#\n",
    "decoded_wgan_synthetic_data = data_preprocessor.inverse_transform(wgan_synthetic_data)\n",
    "# --------------------- Saving ---------------------#\n",
    "decoded_wgan_synthetic_data.to_csv(synt_path / \"WGAN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthius.model import ARF\n",
    "\n",
    "model = ARF(x=train_data, id_column=ID, min_node_size=5, num_trees=50, max_features=0.3)\n",
    "forde = model.forde()\n",
    "synthetic_data_arf = model.forge(n=total_samples)\n",
    "\n",
    "synthetic_data_arf.to_csv(synt_path / \"ARF.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthius-zTqflg9O-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
