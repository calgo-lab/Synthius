{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/.dsw_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-21 15:12:41.287761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-21 15:12:41.320162: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-21 15:12:41.320224: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-21 15:12:41.345208: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-21 15:12:42.829501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from synthius.metric.utils import utils\n",
    "from synthius.utilities import MetricsAggregator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Path(\"data/train.csv\")  # TODO: Change this to the path of the training dataset (to generate synthetic data from)\n",
    "test_data = Path(\"data/test.csv\")  # TODO: Change this to the path of the test dataset (to generate syntehtic data from)\n",
    "synt_path = Path(\"synthetic_data\")  # TODO: Change this to the path of the synthetic data directory (for generated datasets)\n",
    "models_path = Path(\"models\")  # TODO: Change this to the path of the models directory (where you store the models trained!)\n",
    "RESULTS_PATH = Path(\"results\")  # TODO: Change this to the path of the results directory\n",
    "\n",
    "synthetic_data_paths = [\n",
    "    synt_path / \"ARF.csv\",\n",
    "    synt_path / \"CopulaGAN.csv\",\n",
    "    synt_path / \"CTGAN.csv\",\n",
    "    synt_path / \"GaussianCopula.csv\",\n",
    "    synt_path / \"GaussianMultivariate.csv\",\n",
    "    synt_path / \"TVAE.csv\",\n",
    "    # synt_path / \"WGAN.csv\", broken!\n",
    "]\n",
    "\n",
    "\n",
    "TARGET = \"target_binary\"  # TODO: Change this to the target column\n",
    "POS_LABEL = 1  # TODO: Change this to the positive label\n",
    "# If it's a binary classification problem, use TRUE without quotation marks\n",
    "ID = None  # TODO: Change this to the ID column if exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the key fields, sensitive fields, and auxiliary columns as per your data. Below is an example of how it should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_fields = [\n",
    "    \"Age\",\n",
    "    \"Education\",\n",
    "    \"Occupation\",\n",
    "    \"Income\",\n",
    "    \"Marital-status\",\n",
    "    \"Native-country\",\n",
    "    \"Relationship\",\n",
    "]\n",
    "\n",
    "sensitive_fields = [\"Race\", \"Sex\"]\n",
    "\n",
    "\n",
    "aux_cols = [\n",
    "    [\"Occupation\", \"Education\", \"Education-num\", \"Hours-per-week\", \"Capital-loss\", \"Capital-gain\"],\n",
    "    [\"Race\", \"Sex\", \"Fnlwgt\", \"Age\", \"Native-country\", \"Workclass\", \"Marital-status\", \"Relationship\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MetricsAggregator.__init__() got an unexpected keyword argument 'inference_n_attacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# We make sure we use the clean columns from the data\u001b[39;00m\n\u001b[32m      2\u001b[39m inference_all_columns = utils.clean_columns(pd.read_csv(test_data)).columns\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m metrics_result = \u001b[43mMetricsAggregator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreal_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynthetic_data_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynthetic_data_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrol_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_fields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msensitive_fields\u001b[49m\u001b[43m=\u001b[49m\u001b[43msensitive_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_scaler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMinMaxScaler\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msinglingout_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmultivariate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43msinglingout_n_attacks\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43msinglingout_n_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlinkability_n_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlinkability_n_attacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlinkability_aux_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutility_test_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutility_models_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#inference_all_columns=inference_all_columns,\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#inference_use_custom_model=True,\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#inference_sample_attacks=False,\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43minference_n_attacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPOS_LABEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwant_parallel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneed_split\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: MetricsAggregator.__init__() got an unexpected keyword argument 'inference_n_attacks'"
     ]
    }
   ],
   "source": [
    "# We make sure we use the clean columns from the data\n",
    "inference_all_columns = utils.clean_columns(pd.read_csv(test_data)).columns\n",
    "\n",
    "metrics_result = MetricsAggregator(\n",
    "    real_data_path=train_data,\n",
    "    synthetic_data_paths=synthetic_data_paths,\n",
    "    control_data=test_data,\n",
    "    key_fields=key_fields,\n",
    "    sensitive_fields=sensitive_fields,\n",
    "    distance_scaler=\"MinMaxScaler\",\n",
    "    singlingout_mode=\"multivariate\",\n",
    "    singlingout_n_attacks=6_000,\n",
    "    singlingout_n_cols=7,\n",
    "    linkability_n_neighbors=500,\n",
    "    linkability_n_attacks=None,\n",
    "    linkability_aux_cols=aux_cols,\n",
    "    id_column=ID,\n",
    "    utility_test_path=test_data,\n",
    "    utility_models_path=models_path,\n",
    "    #inference_all_columns=inference_all_columns,\n",
    "    #inference_use_custom_model=True,\n",
    "    #inference_sample_attacks=False,\n",
    "    #inference_n_attacks=None,\n",
    "    label_column=TARGET,\n",
    "    pos_label=POS_LABEL,\n",
    "    want_parallel=False,\n",
    "    need_split=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the evaluation method\n",
    "\n",
    "The `MetricsAggregator` class provides three distinct modes to evaluate metrics, depending on your use case. Below is a detailed explanation and examples for each mode:\n",
    "\n",
    "### 1. Running Metrics for Synthetic Models Only\n",
    "\n",
    "This mode calculates metrics exclusively for synthetic models, without involving the original dataset. Use this when you want to evaluate the performance or properties of your synthetic data independently.\n",
    "\n",
    "```\n",
    "metrics_result.run_metrics_for_models()\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n",
    "### 2. Running Metrics for the Original Dataset Only\n",
    "\n",
    "This mode calculates metrics for the original dataset by splitting train dataset into two equal parts (50-50 split). It is useful for benchmarking or validating your metrics.\n",
    "\n",
    "```\n",
    "metrics_result.run_metrics_for_original()\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n",
    "\n",
    "### 3. Running Metrics for Both Synthetic Models and the Original Dataset\n",
    "\n",
    "This mode evaluates metrics for both synthetic models and the original dataset.\n",
    "```\n",
    "metrics_result.run_all_with_original()\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n",
    "### Update Existing Results with Original Dataset Values\n",
    "\n",
    "If you want to update the results for synthetic models with the original dataset results without re-running all the metrics, follow these steps:\n",
    "\n",
    "```\n",
    "# Load the current results\n",
    "metrics_result = MetricsAggregator.load_results(Path(\"res.pkl\"))\n",
    "\n",
    "# Run the calculation for the original dataset\n",
    "metrics_result.run_metrics_for_original()\n",
    "\n",
    "# Update the utility metric to include the original dataset results\n",
    "metrics_result.run_or_update_metric(\"Utility\")\n",
    "\n",
    "# Display the updated results\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_result.run_all_with_original()\n",
    "display(metrics_result.all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_all_columns = utils.clean_columns(pd.read_csv(test_data)).columns\n",
    "\n",
    "metrics_result = MetricsAggregator(\n",
    "    real_data_path=train_data,\n",
    "    synthetic_data_paths=synthetic_data_paths,\n",
    "    control_data=test_data,\n",
    "    key_fields=key_fields,\n",
    "    sensitive_fields=sensitive_fields,\n",
    "    distance_scaler=\"MinMaxScaler\",\n",
    "    singlingout_mode=\"multivariate\",\n",
    "    singlingout_n_attacks=6_000,\n",
    "    singlingout_n_cols=7,\n",
    "    linkability_n_neighbors=500,\n",
    "    linkability_n_attacks=None,\n",
    "    linkability_aux_cols=aux_cols,\n",
    "    id_column=ID,\n",
    "    utility_test_path=test_data,\n",
    "    utility_models_path=models_path,\n",
    "    inference_all_columns=inference_all_columns,\n",
    "    inference_use_custom_model=True,\n",
    "    inference_sample_attacks=False,\n",
    "    inference_n_attacks=None,\n",
    "    label_column=TARGET,\n",
    "    pos_label=POS_LABEL,\n",
    "    want_parallel=False,\n",
    "    need_split=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dsw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
