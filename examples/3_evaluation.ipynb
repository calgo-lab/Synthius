{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from synthius.metric.utils import utils\n",
    "from synthius.utilities import MetricsAggregator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Path(\"PATH_TO_TRAIN_DATASET_AS_CSV\")  # TODO: Change this to the path of the training dataset\n",
    "test_data = Path(\"PATH_TO_TEST_DATASET_AS_CSV\")  # TODO: Change this to the path of the test dataset\n",
    "synt_path = Path(\"PATH_TO_SYNTHETIC_DATA_DIRECTORY\")  # TODO: Change this to the path of the synthetic data directory\n",
    "models_path = Path(\"PATH_TO_MODELS_DIRECTORY\")  # TODO: Change this to the path of the models directory\n",
    "RESULTS_PATH = Path(\"PATH_TO_RESULTS_DIRECTORY\")  # TODO: Change this to the path of the results directory\n",
    "\n",
    "synthetic_data_paths = [\n",
    "    synt_path / \"ARF.csv\",\n",
    "    synt_path / \"CopulaGAN.csv\",\n",
    "    synt_path / \"CTGAN.csv\",\n",
    "    synt_path / \"GaussianCopula.csv\",\n",
    "    synt_path / \"GaussianMultivariate.csv\",\n",
    "    synt_path / \"TVAE.csv\",\n",
    "    synt_path / \"WGAN.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "TARGET = \"TARGET_COLUMN\"  # TODO: Change this to the target column\n",
    "POS_LABEL = \"POSITIVE_LABEL\"  # TODO: Change this to the positive label\n",
    "# If it's a binary classification problem, use TRUE without quotation marks\n",
    "ID = None  # TODO: Change this to the ID column if exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the key fields, sensitive fields, and auxiliary columns as per your data. Below is an example of how it should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_fields = [\n",
    "    \"Age\",\n",
    "    \"Education\",\n",
    "    \"Occupation\",\n",
    "    \"Income\",\n",
    "    \"Marital-status\",\n",
    "    \"Native-country\",\n",
    "    \"Relationship\",\n",
    "]\n",
    "\n",
    "sensitive_fields = [\"Race\", \"Sex\"]\n",
    "\n",
    "\n",
    "aux_cols = [\n",
    "    [\"Occupation\", \"Education\", \"Education-num\", \"Hours-per-week\", \"Capital-loss\", \"Capital-gain\"],\n",
    "    [\"Race\", \"Sex\", \"Fnlwgt\", \"Age\", \"Native-country\", \"Workclass\", \"Marital-status\", \"Relationship\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make sure we use the clean columns from the data\n",
    "inference_all_columns = utils.clean_columns(pd.read_csv(test_data)).columns\n",
    "\n",
    "metrics_result = MetricsAggregator(\n",
    "    real_data_path=train_data,\n",
    "    synthetic_data_paths=synthetic_data_paths,\n",
    "    control_data=test_data,\n",
    "    key_fields=key_fields,\n",
    "    sensitive_fields=sensitive_fields,\n",
    "    distance_scaler=\"MinMaxScaler\",\n",
    "    singlingout_mode=\"multivariate\",\n",
    "    singlingout_n_attacks=6_000,\n",
    "    singlingout_n_cols=7,\n",
    "    linkability_n_neighbors=500,\n",
    "    linkability_n_attacks=None,\n",
    "    linkability_aux_cols=aux_cols,\n",
    "    id_column=ID,\n",
    "    utility_test_path=test_data,\n",
    "    utility_models_path=models_path,\n",
    "    inference_all_columns = inference_all_columns,\n",
    "    inference_use_custom_model=True,\n",
    "    inference_sample_attacks=False,\n",
    "    inference_n_attacks=None,\n",
    "    label_column=TARGET,\n",
    "    pos_label=POS_LABEL,\n",
    "    want_parallel=False,\n",
    "    need_split=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the evaluation method\n",
    "\n",
    "The `MetricsAggregator` class provides three distinct modes to evaluate metrics, depending on your use case. Below is a detailed explanation and examples for each mode:\n",
    "\n",
    "### 1. Running Metrics for Synthetic Models Only\n",
    "\n",
    "This mode calculates metrics exclusively for synthetic models, without involving the original dataset. Use this when you want to evaluate the performance or properties of your synthetic data independently.\n",
    "\n",
    "```\n",
    "metrics_result.run_metrics_for_models()\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n",
    "### 2. Running Metrics for the Original Dataset Only\n",
    "\n",
    "This mode calculates metrics for the original dataset by splitting train dataset into two equal parts (50-50 split). It is useful for benchmarking or validating your metrics.\n",
    "\n",
    "```\n",
    "metrics_result.run_metrics_for_original()\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n",
    "\n",
    "### 3. Running Metrics for Both Synthetic Models and the Original Dataset\n",
    "\n",
    "This mode evaluates metrics for both synthetic models and the original dataset.\n",
    "```\n",
    "metrics_result.run_all_with_original()\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n",
    "### Update Existing Results with Original Dataset Values\n",
    "\n",
    "If you want to update the results for synthetic models with the original dataset results without re-running all the metrics, follow these steps:\n",
    "\n",
    "```\n",
    "# Load the current results\n",
    "metrics_result = MetricsAggregator.load_results(Path(\"res.pkl\"))\n",
    "\n",
    "# Run the calculation for the original dataset\n",
    "metrics_result.run_metrics_for_original()\n",
    "\n",
    "# Update the utility metric to include the original dataset results\n",
    "metrics_result.run_or_update_metric(\"Utility\")\n",
    "\n",
    "# Display the updated results\n",
    "display(metrics_result.all_results)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_result.run_all_with_original()\n",
    "display(metrics_result.all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_all_columns = utils.clean_columns(pd.read_csv(test_data)).columns\n",
    "\n",
    "metrics_result = MetricsAggregator(\n",
    "    real_data_path=train_data,\n",
    "    synthetic_data_paths=synthetic_data_paths,\n",
    "    control_data=test_data,\n",
    "    key_fields=key_fields,\n",
    "    sensitive_fields=sensitive_fields,\n",
    "    distance_scaler=\"MinMaxScaler\",\n",
    "    singlingout_mode=\"multivariate\",\n",
    "    singlingout_n_attacks=6_000,\n",
    "    singlingout_n_cols=7,\n",
    "    linkability_n_neighbors=500,\n",
    "    linkability_n_attacks=None,\n",
    "    linkability_aux_cols=aux_cols,\n",
    "    id_column=ID,\n",
    "    utility_test_path=test_data,\n",
    "    utility_models_path=models_path,\n",
    "    inference_all_columns = inference_all_columns,\n",
    "    inference_use_custom_model=True,\n",
    "    inference_sample_attacks=False,\n",
    "    inference_n_attacks=None,\n",
    "    label_column=TARGET,\n",
    "    pos_label=POS_LABEL,\n",
    "    want_parallel=False,\n",
    "    need_split=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic_data-OetqL8uo-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
